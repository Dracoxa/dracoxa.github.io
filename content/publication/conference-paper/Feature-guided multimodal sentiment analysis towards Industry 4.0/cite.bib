@article{YU2022107961,
title = {Feature-guided Multimodal Sentiment Analysis towards Industry 4.0},
journal = {Computers and Electrical Engineering},
volume = {100},
pages = {107961},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107961},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622002373},
author = {Bihui Yu and Jingxuan Wei and Bo Yu and Xingye Cai and Ke Wang and Huajun Sun and Liping Bu and Xiaowei Chen},
keywords = {Industry 4.0, Artificial Intelligence, Sentiment recognition, Multimodal, Attention mechanism},
abstract = {Abstarct
Combining Artificial Intelligence (AI) to process rich media information has become an important part of Industry 4.0. Sentiment recognition in AI aims to analyze user emotions contained in rich media to facilitate service enhancement. Previous research on sentiment recognition has mainly focused on academia, and few have discussed algorithmic applications and innovations in industry. In this paper, we propose a general approach for multimodal sentiment recognition for images and text. The method provides a new approach for processing rich media information by fully considering the internal features of each modality itself as well as the correlations between the modalities. In the dataset constructed in this paper, the accuracy rate is improved by more than 4% compared with the method using single modality. The effectiveness and generality of the method in multimodal sentiment recognition is demonstrated by extending the experiments with a multimodal public dataset.}
}