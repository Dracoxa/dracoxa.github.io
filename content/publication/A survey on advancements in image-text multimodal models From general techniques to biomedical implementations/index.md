---
title: 'A survey on advancements in image-text multimodal models: From general techniques to biomedical implementations'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - Ruifeng Guo
  - Jingxuan Wei
  - Linzhuang Sun


# Author notes (optional)
author_notes:
  - 'First author'
  - Ruifeng Guo

date: '2024-06-03T15:57:35Z'
doi: 'https://doi.org/10.1016/j.compbiomed.2024.108709'

# Schedule page publish date (NOT publication's date).
publishDate: '2024-06-03T15:57:35Z'

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
#publication_types: ['paper-conference']

# Publication name and optional abbreviated publication name.
publication_short: In *Computers in biology and medicine*

abstract: With the significant advancements of Large Language Models (LLMs) in the field of Natural Language Processing (NLP), the development of image–text multimodal models has garnered widespread attention. Current surveys on image–text multimodal models mainly focus on representative models or application domains, but lack a review on how general technical models influence the development of domain-specific models, which is crucial for domain researchers. Based on this, this paper first reviews the technological evolution of image–text multimodal models, from early explorations of feature space to visual language encoding structures, and then to the latest large model architectures. Next, from the perspective of technological evolution, we explain how the development of general image–text multimodal technologies promotes the progress of multimodal technologies in the biomedical field, as well as the importance and complexity of specific datasets in the biomedical domain. Then, centered on the tasks of image–text multimodal models, we analyze their common components and challenges. After that, we summarize the architecture, components, and data of general image–text multimodal models, and introduce the applications and improvements of image–text multimodal models in the biomedical field. Finally, we categorize the challenges faced in the development and application of general models into external factors and intrinsic factors, further refining them into 2 external factors and 5 intrinsic factors, and propose targeted solutions, providing guidance for future research directions. For more details and data, please visit our GitHub page  https://github.com/i2vec/A-survey-on-image-text-multimodal-models.

# Summary. An optional shortened abstract.
summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.

tags: []

# Display this page in the Featured widget?
featured: true

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: 'content/publication/conference-paper/2411.11916v1.pdf'
# https://www.sciencedirect.com/science/article/abs/pii/S0010482524007947



# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - example

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
---


