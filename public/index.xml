<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>首页 | 多模态认知智能实验室</title>
    <link>http://localhost:1313/</link>
      <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>首页</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 20 Oct 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu_e368a5d79bca84d.png</url>
      <title>首页</title>
      <link>http://localhost:1313/</link>
    </image>
    
    <item>
      <title>ResearchPulse Paper Accepted at ACM MM 2025</title>
      <link>http://localhost:1313/event/aclmm/</link>
      <pubDate>Mon, 20 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/aclmm/</guid>
      <description>&lt;!-- 
Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [_Slides_](https://docs.hugoblox.com/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://docs.hugoblox.com/writing-markdown-latex/).

Further event details, including page elements such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>MM-Verify Paper Accepted at ACL 2025</title>
      <link>http://localhost:1313/event/acl2025/</link>
      <pubDate>Wed, 30 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/acl2025/</guid>
      <description>&lt;!-- 
Slides can be added in a few ways:

- **Create** slides using Wowchemy&#39;s [_Slides_](https://docs.hugoblox.com/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://docs.hugoblox.com/writing-markdown-latex/).

Further event details, including page elements such as image galleries, can be added to the body of this page. --&gt;
</description>
    </item>
    
    <item>
      <title>From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing</title>
      <link>http://localhost:1313/publication/conference-paper/from-words-to-structured/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/from-words-to-structured/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Words to Structured Visuals Paper Accepted at CVPR 2025</title>
      <link>http://localhost:1313/event/cvpr/</link>
      <pubDate>Wed, 11 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/cvpr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulations on CVPR 2025 Publication</title>
      <link>http://localhost:1313/post/congratulations-on-cvpr-2025-publication/</link>
      <pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/congratulations-on-cvpr-2025-publication/</guid>
      <description>&lt;p&gt;中国科学院沈阳计算所多模态认知智能团队“From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing”文章被计算机视觉与模式识别会议(CVPR 2025)接受，CVPR是计算机视觉领域最具权威、最高水平、最具影响力的国际顶级学术会议之一，为CCF A类会议。&lt;/p&gt;
&lt;p&gt;We are excited to celebrate the acceptance of the paper &amp;ldquo;From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing&amp;rdquo; by Jingxuan Wei, Cheng Tan, Qi Chen, Gaowei Wu, Siyuan Li, Zhangyang Gao, Linzhuang Sun, Bihui Yu, and Ruifeng Guo at CVPR 2025!&lt;/p&gt;
&lt;p&gt;This innovative work  presents a pioneering benchmark and framework for text-to-diagram generation and editing. The paper introduces a comprehensive approach to transforming textual descriptions into structured visual diagrams, addressing challenges in automated diagram creation and iterative editing. By establishing a new benchmark, the authors provide a robust evaluation platform for future research in this interdisciplinary domain of computer vision and natural language processing. Their framework leverages advanced techniques to enable precise, context-aware diagram generation, offering significant potential for applications in education, technical documentation, and data visualization.&lt;/p&gt;
&lt;p&gt;This achievement highlights the team&amp;rsquo;s dedication to advancing the integration of language and visual processing, paving the way for more intuitive and automated visualization tools. Congratulations to Jingxuan Wei, Cheng Tan, Qi Chen, Gaowei Wu, Siyuan Li, Zhangyang Gao, Linzhuang Sun, Bihui Yu, and Ruifeng Guo for their outstanding contribution to CVPR 2025!&lt;/p&gt;
&lt;p&gt;Read the full paper here: &lt;a href=&#34;https://arxiv.org/pdf/2411.11916&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/2411.11916&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Faster and More Efficient Subject Image Generation for Text-to-Image Diffusion Models</title>
      <link>http://localhost:1313/publication/conference-paper/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/</link>
      <pubDate>Sun, 06 Oct 2024 15:57:35 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SAM-Wav2lip&#43;&#43;: Enhancing Behavioral Realism in Synthetic Agents Through Audio-Driven Speech and Action Refinement</title>
      <link>http://localhost:1313/publication/conference-paper/sam-wav2lip&#43;&#43;-enhancing-behavioral-realism-in-synthetic-agents-through-audio-driven-speech-and-action-refinement/</link>
      <pubDate>Sun, 06 Oct 2024 15:57:35 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/sam-wav2lip&#43;&#43;-enhancing-behavioral-realism-in-synthetic-agents-through-audio-driven-speech-and-action-refinement/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interpretable and Generalizable Spatiotemporal Predictive Learning with Disentangled Consistency</title>
      <link>http://localhost:1313/publication/conference-paper/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/</link>
      <pubDate>Thu, 22 Aug 2024 15:57:35 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training</title>
      <link>http://localhost:1313/publication/conference-paper/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/</link>
      <pubDate>Wed, 03 Jul 2024 02:56:47 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sentence-Level or Token-Level: A Comprehensive Study on Knowledge Distillation</title>
      <link>http://localhost:1313/publication/conference-paper/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/</link>
      <pubDate>Tue, 23 Apr 2024 08:29:56 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TED-CS: Textual Enhanced Sensitive Video Detection with Common Sense Knowledge</title>
      <link>http://localhost:1313/publication/conference-paper/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/</link>
      <pubDate>Sun, 05 Nov 2023 15:57:35 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework</title>
      <link>http://localhost:1313/publication/conference-paper/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/</link>
      <pubDate>Tue, 25 Jul 2023 15:57:35 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/contact/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>People</title>
      <link>http://localhost:1313/people/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tour</title>
      <link>http://localhost:1313/tour/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/tour/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feature-guided Multimodal Sentiment Analysis towards Industry 4.0</title>
      <link>http://localhost:1313/publication/conference-paper/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/</link>
      <pubDate>Thu, 24 Mar 2022 15:57:35 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
