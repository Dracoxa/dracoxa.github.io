
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["Jingxuan Wei"],"categories":null,"content":"Jingxuan Wei is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1751328000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1751328000,"objectID":"156552cc76ba020c53fdbabef12222b2","permalink":"http://localhost:1313/author/jingxuan-wei/","publishdate":"2025-06-23T00:00:00Z","relpermalink":"/author/jingxuan-wei/","section":"authors","summary":"Jingxuan Wei is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Jingxuan Wei","type":"authors"},{"authors":["Qi Chen"],"categories":null,"content":"Qi Chen is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1751328000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1751328000,"objectID":"926eee230b0a19babdc11ede8be8371a","permalink":"http://localhost:1313/author/qi-chen/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/author/qi-chen/","section":"authors","summary":"Qi Chen is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Qi Chen","type":"authors"},{"authors":["张思博"],"categories":null,"content":"张思博 is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1750636800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1750636800,"objectID":"82ecdf46e3323f53c4aecb3e3541218c","permalink":"http://localhost:1313/author/sibo-zhang/","publishdate":"2025-06-23T00:00:00Z","relpermalink":"/author/sibo-zhang/","section":"authors","summary":"张思博 is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Sibo Zhang","type":"authors"},{"authors":["Bihui Yu"],"categories":null,"content":"Bihui Yu is a Researcher and Doctoral Supervisor at the Shenyang Institute of Computing Technology, Chinese Academy of Sciences, where he serves as the Head of Multimodal Cognitive Intelligence at the Technology Center and Deputy Director of the Liaoning Provincial Multimodal Intelligent Perception and Cognitive Engineering Research Center. His research focuses on big data, artificial intelligence, knowledge engineering (knowledge graphs), and multimodal data processing. He has led and participated in over 20 national, provincial, and municipal research projects, including the National Major Scientific Instrument Development Project and the National Key R\u0026amp;D Program. Bihui has published over 40 academic papers in domestic and international conferences and journals, applied for more than 10 national invention patents, and contributed to the development of products such as digital broadcasting terminals, communication scheduling terminals, industrial big data analysis platforms, and knowledge management platforms. He has extensive experience in big data, knowledge engineering, natural language processing, and network communication applications\n","date":1728230255,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1728230255,"objectID":"cfb8515c3dfee36328e2155bdeea93ba","permalink":"http://localhost:1313/author/bihui-yu/","publishdate":"2024-10-06T15:57:35Z","relpermalink":"/author/bihui-yu/","section":"authors","summary":"Bihui Yu is a Researcher and Doctoral Supervisor at the Shenyang Institute of Computing Technology, Chinese Academy of Sciences, where he serves as the Head of Multimodal Cognitive Intelligence at the Technology Center and Deputy Director of the Liaoning Provincial Multimodal Intelligent Perception and Cognitive Engineering Research Center. His research focuses on big data, artificial intelligence, knowledge engineering (knowledge graphs), and multimodal data processing. He has led and participated in over 20 national, provincial, and municipal research projects, including the National Major Scientific Instrument Development Project and the National Key R\u0026D Program. Bihui has published over 40 academic papers in domestic and international conferences and journals, applied for more than 10 national invention patents, and contributed to the development of products such as digital broadcasting terminals, communication scheduling terminals, industrial big data analysis platforms, and knowledge management platforms. He has extensive experience in big data, knowledge engineering, natural language processing, and network communication applications\n","tags":null,"title":"Bihui Yu","type":"authors"},{"authors":["姚征兵"],"categories":null,"content":"张思博 is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1728230255,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1728230255,"objectID":"1e6937ff0affcdc255305abbb3874c4d","permalink":"http://localhost:1313/author/zhengbing-yao/","publishdate":"2024-10-06T15:57:35Z","relpermalink":"/author/zhengbing-yao/","section":"authors","summary":"张思博 is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Zhengbing Yao","type":"authors"},{"authors":["贾彩军"],"categories":null,"content":"贾彩军 is a master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9820560ac29db6fbe3b9f4c136bd9248","permalink":"http://localhost:1313/author/caijun-jia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/caijun-jia/","section":"authors","summary":"贾彩军 is a master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Caijun Jia","type":"authors"},{"authors":["Dawei Liu"],"categories":null,"content":"Dawei Liu is a Master candidate with research interests iMultimodal Generation and Digital Human. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b670986c2f24df805705c1d21e713e45","permalink":"http://localhost:1313/author/dawei-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dawei-liu/","section":"authors","summary":"Dawei Liu is a Master candidate with research interests iMultimodal Generation and Digital Human. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Dawei Liu","type":"authors"},{"authors":["Gaowei Wu"],"categories":null,"content":"Gaowei Wu is a Master candidate with research interests in Agent and Retrieval-Augmented Generation (RAG). His work focuses on advancing intelligent agent systems and enhanced generation techniques.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4040019e893938f57df21441a40e78eb","permalink":"http://localhost:1313/author/gaowei-wu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/gaowei-wu/","section":"authors","summary":"Gaowei Wu is a Master candidate with research interests in Agent and Retrieval-Augmented Generation (RAG). His work focuses on advancing intelligent agent systems and enhanced generation techniques.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Gaowei Wu","type":"authors"},{"authors":["Hexuan Jin"],"categories":null,"content":"Hexuan Jin is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"84f9f7b51ba4d9c1557ebdba69a155dc","permalink":"http://localhost:1313/author/hexuan-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hexuan-jin/","section":"authors","summary":"Hexuan Jin is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Hexuan Jin","type":"authors"},{"authors":["Mingfei Jin"],"categories":null,"content":"Mingfei Jin is a Master candidate with research interests in large language models, reinforcement learning, and reasoning chains. His work focuses on advancing AI reasoning and learning systems.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ca3ac3f5707f8bbc6275328e148d4189","permalink":"http://localhost:1313/author/mingfei-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mingfei-jin/","section":"authors","summary":"Mingfei Jin is a Master candidate with research interests in large language models, reinforcement learning, and reasoning chains. His work focuses on advancing AI reasoning and learning systems.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Mingfei Jin","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"http://localhost:1313/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["Jingxuan Wei","Cheng Tan","Qi Chen"],"categories":null,"content":"","date":1751328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751328000,"objectID":"67b1fdc1b98e518a9ee51d1b443d00f6","permalink":"http://localhost:1313/publication/from-words-to-structured/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/from-words-to-structured/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing","type":"publication"},{"authors":["Sibo Zhang"],"categories":null,"content":"","date":1750636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1750636800,"objectID":"72aecfa97fc361dd02cc9180cebb5a0c","permalink":"http://localhost:1313/publication/preprint/","publishdate":"2025-06-23T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"EEGTCW introduces a new method for decoding Chinese words from EEG signals, enhancing brain-computer interface technologies.","tags":["EEG","Chinese Words Decoding","Brain-Computer Interface"],"title":"EEGTCW: Electroencephalogram-based Chinese Words Decoding","type":"publication"},{"authors":["Jingxuan Wei"],"categories":null,"content":"","date":1750636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1750636800,"objectID":"f5703b05bdee62f11e0a6755f60a60d4","permalink":"http://localhost:1313/publication/multifaceted-assessment-and/","publishdate":"2025-06-23T00:00:00Z","relpermalink":"/publication/multifaceted-assessment-and/","section":"publication","summary":"With the evolution of artificial intelligence technology and the exploration of brain science, more and more researchers are committed to the decoding of brain signals, and the application of brain-computer interface(BCI) is constantly updated. Electroencephalogram(EEG) signals are non-invasive signals that have attracted increasing attention due to their non-transplantability and high temporal resolution. This paper focuses on the decoding of EEG signals to Chinese words, and proposes a novel framework, EEGTCW, which is based on the BiGRU-Attention-CNN classification model and data augmentation method to decode EEG signals into categories corresponding to Chinese words on a self-built dataset. The classification accuracy reaches 0.88, while exploring the gener-alization performance of the model under different batches of a single subject and generalization performance across subjects. It has certain reference value for the improvement of BCI assistant system for speech disorder people.","tags":[null],"title":"Multifaceted Assessment and Resolution of Hallucinations in Large Visual-Language Models","type":"publication"},{"authors":null,"categories":null,"content":"中国科学院沈阳计算所多模态认知智能团队“From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing”文章被计算机视觉与模式识别会议(CVPR 2025)接受，CVPR是计算机视觉领域最具权威、最高水平、最具影响力的国际顶级学术会议之一，为CCF A类会议。\nWe are excited to celebrate the acceptance of the paper “From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing” by Jingxuan Wei, Cheng Tan, Qi Chen, Gaowei Wu, Siyuan Li, Zhangyang Gao, Linzhuang Sun, Bihui Yu, and Ruifeng Guo at CVPR 2025!\nThis innovative work presents a pioneering benchmark and framework for text-to-diagram generation and editing. The paper introduces a comprehensive approach to transforming textual descriptions into structured visual diagrams, addressing challenges in automated diagram creation and iterative editing. By establishing a new benchmark, the authors provide a robust evaluation platform for future research in this interdisciplinary domain of computer vision and natural language processing. Their framework leverages advanced techniques to enable precise, context-aware diagram generation, offering significant potential for applications in education, technical documentation, and data visualization.\nThis achievement highlights the team’s dedication to advancing the integration of language and visual processing, paving the way for more intuitive and automated visualization tools. Congratulations to Jingxuan Wei, Cheng Tan, Qi Chen, Gaowei Wu, Siyuan Li, Zhangyang Gao, Linzhuang Sun, Bihui Yu, and Ruifeng Guo for their outstanding contribution to CVPR 2025!\nRead the full paper here: https://arxiv.org/pdf/2411.11916\n","date":1740614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740614400,"objectID":"26ba21cfc75e220d529131a7f9fa8ac4","permalink":"http://localhost:1313/post/congratulations-on-cvpr-2025-publication/","publishdate":"2025-02-27T00:00:00Z","relpermalink":"/post/congratulations-on-cvpr-2025-publication/","section":"post","summary":"中国科学院沈阳计算所多模态认知智能团队“From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing”文章被计算机视觉与模式识别会议(CVPR 2025)接受，CVPR是计算机视觉领域最具权威、最高水平、最具影响力的国际顶级学术会议之一，为CCF A类会议。\n","tags":null,"title":"Congratulations on CVPR 2025 Publication","type":"post"},{"authors":["Bihui Yu","Zhengbing Yao","Jingxuan Wei"],"categories":null,"content":"","date":1728230255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728230255,"objectID":"b2171c69f4b346c6d45a666eb7b655bb","permalink":"http://localhost:1313/publication/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/","publishdate":"2024-10-06T15:57:35Z","relpermalink":"/publication/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Faster and More Efficient Subject Image Generation for Text-to-Image Diffusion Models","type":"publication"},{"authors":["Bihui Yu","Dawei Liu","Huiyang Shi"],"categories":null,"content":"","date":1728230255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728230255,"objectID":"1083139c7797649c7fd35844470c8771","permalink":"http://localhost:1313/publication/sam-wav2lip++-enhancing-behavioral-realism-in-synthetic-agents-through-audio-driven-speech-and-action-refinement/","publishdate":"2024-10-06T15:57:35Z","relpermalink":"/publication/sam-wav2lip++-enhancing-behavioral-realism-in-synthetic-agents-through-audio-driven-speech-and-action-refinement/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"SAM-Wav2lip++: Enhancing Behavioral Realism in Synthetic Agents Through Audio-Driven Speech and Action Refinement","type":"publication"},{"authors":["Jingxuan Wei","Cheng Tan","Zhangyang Gao"],"categories":null,"content":"","date":1724342255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724342255,"objectID":"d7e9ee5c02984ecdd2f90a84e2035ed6","permalink":"http://localhost:1313/publication/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/","publishdate":"2024-08-22T15:57:35Z","relpermalink":"/publication/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Interpretable and Generalizable Spatiotemporal Predictive Learning with Disentangled Consistency","type":"publication"},{"authors":["Cheng Tan","Jingxuan Wei","Zhangyang Gao"],"categories":null,"content":"","date":1719975407,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719975407,"objectID":"ae53aedf050d11e3faeabfe7e7ce6334","permalink":"http://localhost:1313/publication/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/","publishdate":"2024-07-03T02:56:47Z","relpermalink":"/publication/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training","type":"publication"},{"authors":["Ruifeng Guo","Jingxuan Wei","Linzhuang Sun"],"categories":null,"content":"","date":1717430255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717430255,"objectID":"d7c90ac6e03b5a8e16b82ea6c26ed8cb","permalink":"http://localhost:1313/publication/a-survey-on-advancements-in-image-text-multimodal-models-from-general-techniques-to-biomedical-implementations/","publishdate":"2024-06-03T15:57:35Z","relpermalink":"/publication/a-survey-on-advancements-in-image-text-multimodal-models-from-general-techniques-to-biomedical-implementations/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"A survey on advancements in image-text multimodal models: From general techniques to biomedical implementations","type":"publication"},{"authors":["Jingxuan Wei","Linzhuang Sun","Yichong Leng"],"categories":null,"content":"","date":1713860996,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713860996,"objectID":"b63ec37a763a92b947aab8cc946ce1c3","permalink":"http://localhost:1313/publication/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/","publishdate":"2024-04-23T08:29:56Z","relpermalink":"/publication/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Sentence-Level or Token-Level: A Comprehensive Study on Knowledge Distillation","type":"publication"},{"authors":["Bihui Yu","Yiman Zhao","Jingxuan Wei"],"categories":null,"content":"","date":1702051055,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702051055,"objectID":"a43140d03fec38599b989aaa8e3a3be8","permalink":"http://localhost:1313/publication/em-cnn-bilstm-causality-extraction-based-on-electra-and-dual-stage-attention-mechanism/","publishdate":"2023-12-08T15:57:35Z","relpermalink":"/publication/em-cnn-bilstm-causality-extraction-based-on-electra-and-dual-stage-attention-mechanism/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"EM-CNN-BiLSTM: Causality extraction based on Electra and Dual-Stage Attention Mechanism","type":"publication"},{"authors":["Bihui Yu","Linzhuang Sun","Jingxuan Wei"],"categories":null,"content":"","date":1699199855,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699199855,"objectID":"c0cd999d92537e663d601acb9468ac23","permalink":"http://localhost:1313/publication/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/","publishdate":"2023-11-05T15:57:35Z","relpermalink":"/publication/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"TED-CS: Textual Enhanced Sensitive Video Detection with Common Sense Knowledge","type":"publication"},{"authors":["Jingxuan Wei","Cheng Tan","Zhangyang Gao"],"categories":null,"content":"","date":1690300655,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690300655,"objectID":"dae503edd8cfa8e01008a31b4578eb5e","permalink":"http://localhost:1313/publication/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/","publishdate":"2023-07-25T15:57:35Z","relpermalink":"/publication/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework","type":"publication"},{"authors":["Bihui Yu","Jingxuan Wei","Shaojie He"],"categories":null,"content":"","date":1681487855,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681487855,"objectID":"501c38b417722a3a6b30a06112096173","permalink":"http://localhost:1313/publication/a-new-multimodal-video-detection-model-and-dataset/","publishdate":"2023-04-14T15:57:35Z","relpermalink":"/publication/a-new-multimodal-video-detection-model-and-dataset/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Construction of Sensitive Image Datasets Based on Generative Methods","type":"publication"},{"authors":["Chang Liu","Jie Zhang","Bihui Yu"],"categories":null,"content":"","date":1681487855,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681487855,"objectID":"eca005f949f1afb855b8af3f0f44588d","permalink":"http://localhost:1313/publication/construction-of-sensitive-image-datasets-based-on-generative-methods/","publishdate":"2023-04-14T15:57:35Z","relpermalink":"/publication/construction-of-sensitive-image-datasets-based-on-generative-methods/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Construction of Sensitive Image Datasets Based on Generative Methods","type":"publication"},{"authors":["Shaojie He","Bihui Yu","Jingxuan Wei"],"categories":null,"content":"","date":1670601455,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670601455,"objectID":"9e08d10f9d66adffc7ba55dfd8c1a522","permalink":"http://localhost:1313/publication/mmes-improved-mayfly-algorithm-based-on-electrostatic-optimization-algorithm/","publishdate":"2022-12-09T15:57:35Z","relpermalink":"/publication/mmes-improved-mayfly-algorithm-based-on-electrostatic-optimization-algorithm/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"MMES: Improved Mayfly Algorithm Based on Electrostatic Optimization Algorithm","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"http://localhost:1313/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"http://localhost:1313/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"http://localhost:1313/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"},{"authors":["Bihui Yu","Jingxuan Wei","Bo Yu"],"categories":null,"content":"","date":1648137455,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648137455,"objectID":"73e0248288bf552349300a5826304089","permalink":"http://localhost:1313/publication/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/","publishdate":"2022-03-24T15:57:35Z","relpermalink":"/publication/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Feature-guided Multimodal Sentiment Analysis towards Industry 4.0","type":"publication"},{"authors":["Bihui Yu","Jingxuan Wei"],"categories":null,"content":"","date":1602691055,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602691055,"objectID":"2f4305bc12585da3f7d4ca95876c899d","permalink":"http://localhost:1313/publication/idcnn-crf-based-domain-named-entity-recognition-method/","publishdate":"2020-10-14T15:57:35Z","relpermalink":"/publication/idcnn-crf-based-domain-named-entity-recognition-method/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"IDCNN-CRF-based domain named entity recognition method","type":"publication"}]