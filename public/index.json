
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["Qi Chen"],"categories":null,"content":"Qi Chen is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1760918400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1760918400,"objectID":"926eee230b0a19babdc11ede8be8371a","permalink":"http://localhost:1313/author/qi-chen/","publishdate":"2025-07-01T00:00:00Z","relpermalink":"/author/qi-chen/","section":"authors","summary":"Qi Chen is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Qi Chen","type":"authors"},{"authors":["Linzhuang Sun"],"categories":null,"content":"Linzhuang Sun is a PhD candidate with research interests in large language models and multimodal large language models. His work focuses on advancing the development and application of these advanced AI technologies.\n","date":1753833600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1753833600,"objectID":"669d651bd015741cfaac7fbbc2630ba4","permalink":"http://localhost:1313/author/linzhuang-sun/","publishdate":"2025-05-15T00:00:00Z","relpermalink":"/author/linzhuang-sun/","section":"authors","summary":"Linzhuang Sun is a PhD candidate with research interests in large language models and multimodal large language models. His work focuses on advancing the development and application of these advanced AI technologies.\n","tags":null,"title":"Linzhuang Sun","type":"authors"},{"authors":["Jingxuan Wei"],"categories":null,"content":"Jingxuan Wei is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1751328000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1751328000,"objectID":"156552cc76ba020c53fdbabef12222b2","permalink":"http://localhost:1313/author/jingxuan-wei/","publishdate":"2025-02-27T00:00:00Z","relpermalink":"/author/jingxuan-wei/","section":"authors","summary":"Jingxuan Wei is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Jingxuan Wei","type":"authors"},{"authors":["Bihui Yu"],"categories":null,"content":"Bihui Yu is a Researcher and Doctoral Supervisor at the Shenyang Institute of Computing Technology, Chinese Academy of Sciences, where he serves as the Head of Multimodal Cognitive Intelligence at the Technology Center and Deputy Director of the Liaoning Provincial Multimodal Intelligent Perception and Cognitive Engineering Research Center. His research focuses on big data, artificial intelligence, knowledge engineering (knowledge graphs), and multimodal data processing. He has led and participated in over 20 national, provincial, and municipal research projects, including the National Major Scientific Instrument Development Project and the National Key R\u0026amp;D Program. Bihui has published over 40 academic papers in domestic and international conferences and journals, applied for more than 10 national invention patents, and contributed to the development of products such as digital broadcasting terminals, communication scheduling terminals, industrial big data analysis platforms, and knowledge management platforms. He has extensive experience in big data, knowledge engineering, natural language processing, and network communication applications\n","date":1749600000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1749600000,"objectID":"cfb8515c3dfee36328e2155bdeea93ba","permalink":"http://localhost:1313/author/bihui-yu/","publishdate":"2025-02-27T00:00:00Z","relpermalink":"/author/bihui-yu/","section":"authors","summary":"Bihui Yu is a Researcher and Doctoral Supervisor at the Shenyang Institute of Computing Technology, Chinese Academy of Sciences, where he serves as the Head of Multimodal Cognitive Intelligence at the Technology Center and Deputy Director of the Liaoning Provincial Multimodal Intelligent Perception and Cognitive Engineering Research Center. His research focuses on big data, artificial intelligence, knowledge engineering (knowledge graphs), and multimodal data processing. He has led and participated in over 20 national, provincial, and municipal research projects, including the National Major Scientific Instrument Development Project and the National Key R\u0026D Program. Bihui has published over 40 academic papers in domestic and international conferences and journals, applied for more than 10 national invention patents, and contributed to the development of products such as digital broadcasting terminals, communication scheduling terminals, industrial big data analysis platforms, and knowledge management platforms. He has extensive experience in big data, knowledge engineering, natural language processing, and network communication applications\n","tags":null,"title":"Bihui Yu","type":"authors"},{"authors":["Gaowei Wu"],"categories":null,"content":"Gaowei Wu is a Master candidate with research interests in Agent and Retrieval-Augmented Generation (RAG). His work focuses on advancing intelligent agent systems and enhanced generation techniques.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1749600000,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1749600000,"objectID":"4040019e893938f57df21441a40e78eb","permalink":"http://localhost:1313/author/gaowei-wu/","publishdate":"2025-02-27T00:00:00Z","relpermalink":"/author/gaowei-wu/","section":"authors","summary":"Gaowei Wu is a Master candidate with research interests in Agent and Retrieval-Augmented Generation (RAG). His work focuses on advancing intelligent agent systems and enhanced generation techniques.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Gaowei Wu","type":"authors"},{"authors":["Zhengbing Yao"],"categories":null,"content":"Zhengbing Yao is a Master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1728230255,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1728230255,"objectID":"1e6937ff0affcdc255305abbb3874c4d","permalink":"http://localhost:1313/author/zhengbing-yao/","publishdate":"2024-10-06T15:57:35Z","relpermalink":"/author/zhengbing-yao/","section":"authors","summary":"Zhengbing Yao is a Master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Zhengbing Yao","type":"authors"},{"authors":["Caijun Jia"],"categories":null,"content":"Caijun Jia is a master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9820560ac29db6fbe3b9f4c136bd9248","permalink":"http://localhost:1313/author/caijun-jia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/caijun-jia/","section":"authors","summary":"Caijun Jia is a master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Caijun Jia","type":"authors"},{"authors":["Dawei Liu"],"categories":null,"content":"Dawei Liu is a Master candidate with research interests iMultimodal Generation and Digital Human. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b670986c2f24df805705c1d21e713e45","permalink":"http://localhost:1313/author/dawei-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/dawei-liu/","section":"authors","summary":"Dawei Liu is a Master candidate with research interests iMultimodal Generation and Digital Human. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Dawei Liu","type":"authors"},{"authors":["Hexuan Jin"],"categories":null,"content":"Hexuan Jin is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"84f9f7b51ba4d9c1557ebdba69a155dc","permalink":"http://localhost:1313/author/hexuan-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/hexuan-jin/","section":"authors","summary":"Hexuan Jin is a Master candidate with research interests in Multimodal Large Language Models (MLLM) and Agent systems. His work focuses on integrating multimodal data and intelligent agents.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Hexuan Jin","type":"authors"},{"authors":["Mingfei Jin"],"categories":null,"content":"Mingfei Jin is a Master candidate with research interests in large language models, reinforcement learning, and reasoning chains. His work focuses on advancing AI reasoning and learning systems.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ca3ac3f5707f8bbc6275328e148d4189","permalink":"http://localhost:1313/author/mingfei-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mingfei-jin/","section":"authors","summary":"Mingfei Jin is a Master candidate with research interests in large language models, reinforcement learning, and reasoning chains. His work focuses on advancing AI reasoning and learning systems.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","tags":null,"title":"Mingfei Jin","type":"authors"},{"authors":["Sibo Zhang"],"categories":null,"content":"Sibo Zhang is a Master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"82ecdf46e3323f53c4aecb3e3541218c","permalink":"http://localhost:1313/author/sibo-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sibo-zhang/","section":"authors","summary":"Sibo Zhang is a Master candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.\n","tags":null,"title":"Sibo Zhang","type":"authors"},{"authors":["Qi Chen","et al."],"categories":null,"content":" ","date":1760918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1760918400,"objectID":"82fef7c5679c9e31eed7f1eae0a1baf3","permalink":"http://localhost:1313/event/aclmm/","publishdate":"2025-07-01T00:00:00Z","relpermalink":"/event/aclmm/","section":"event","summary":"Our paper on scientific inference through multi-document analysis accepted at CCF-A conference.","tags":["multimodal","scientific inference","CCF-A"],"title":"ResearchPulse Paper Accepted at ACM MM 2025","type":"event"},{"authors":["Linzhuang Sun","et al."],"categories":null,"content":" ","date":1753833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1753833600,"objectID":"655ce937376edae948a207a75f65dec3","permalink":"http://localhost:1313/event/acl2025/","publishdate":"2025-05-15T00:00:00Z","relpermalink":"/event/acl2025/","section":"event","summary":"Our work on enhancing multimodal reasoning with verification chains accepted at ACL.","tags":["multimodal reasoning","verification","CCF-A"],"title":"MM-Verify Paper Accepted at ACL 2025","type":"event"},{"authors":["Jingxuan Wei","Cheng Tan","Qi Chen"],"categories":null,"content":"","date":1751328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751328000,"objectID":"3af3e35197598379e87da91f582e279e","permalink":"http://localhost:1313/publication/conference-paper/from-words-to-structured/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/from-words-to-structured/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing","type":"publication"},{"authors":["Jingxuan Wei","Cheng Tan","Qi Chen","Gaowei Wu","Siyuan Li","Zhangyang Gao","Linzhuang Sun","Bihui Yu","Ruifeng Guo"],"categories":null,"content":"","date":1749600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1749600000,"objectID":"522273ca1870c28d608fe62baca9db22","permalink":"http://localhost:1313/event/cvpr/","publishdate":"2025-02-27T00:00:00Z","relpermalink":"/event/cvpr/","section":"event","summary":"Our groundbreaking work on text-to-diagram generation accepted at premier computer vision conference.","tags":["text-to-diagram","computer vision","NLP","CCF-A"],"title":"From Words to Structured Visuals Paper Accepted at CVPR 2025","type":"event"},{"authors":null,"categories":null,"content":"中国科学院沈阳计算所多模态认知智能团队“From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing”文章被计算机视觉与模式识别会议(CVPR 2025)接受，CVPR是计算机视觉领域最具权威、最高水平、最具影响力的国际顶级学术会议之一，为CCF A类会议。\nWe are excited to celebrate the acceptance of the paper “From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing” by Jingxuan Wei, Cheng Tan, Qi Chen, Gaowei Wu, Siyuan Li, Zhangyang Gao, Linzhuang Sun, Bihui Yu, and Ruifeng Guo at CVPR 2025!\nThis innovative work presents a pioneering benchmark and framework for text-to-diagram generation and editing. The paper introduces a comprehensive approach to transforming textual descriptions into structured visual diagrams, addressing challenges in automated diagram creation and iterative editing. By establishing a new benchmark, the authors provide a robust evaluation platform for future research in this interdisciplinary domain of computer vision and natural language processing. Their framework leverages advanced techniques to enable precise, context-aware diagram generation, offering significant potential for applications in education, technical documentation, and data visualization.\nThis achievement highlights the team’s dedication to advancing the integration of language and visual processing, paving the way for more intuitive and automated visualization tools. Congratulations to Jingxuan Wei, Cheng Tan, Qi Chen, Gaowei Wu, Siyuan Li, Zhangyang Gao, Linzhuang Sun, Bihui Yu, and Ruifeng Guo for their outstanding contribution to CVPR 2025!\nRead the full paper here: https://arxiv.org/pdf/2411.11916\n","date":1740614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740614400,"objectID":"26ba21cfc75e220d529131a7f9fa8ac4","permalink":"http://localhost:1313/post/congratulations-on-cvpr-2025-publication/","publishdate":"2025-02-27T00:00:00Z","relpermalink":"/post/congratulations-on-cvpr-2025-publication/","section":"post","summary":"中国科学院沈阳计算所多模态认知智能团队“From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing”文章被计算机视觉与模式识别会议(CVPR 2025)接受，CVPR是计算机视觉领域最具权威、最高水平、最具影响力的国际顶级学术会议之一，为CCF A类会议。\n","tags":null,"title":"Congratulations on CVPR 2025 Publication","type":"post"},{"authors":["Bihui Yu","Zhengbing Yao","Jingxuan Wei"],"categories":null,"content":"","date":1728230255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728230255,"objectID":"7f30433214cec77cb99fe0622c89c85f","permalink":"http://localhost:1313/publication/conference-paper/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/","publishdate":"2024-10-06T15:57:35Z","relpermalink":"/publication/conference-paper/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Faster and More Efficient Subject Image Generation for Text-to-Image Diffusion Models","type":"publication"},{"authors":["Guiyong Chang,","Liping Bu,","Jingxuan Wei","Linzhuang Sun","Dawei Liu"],"categories":null,"content":"","date":1728230255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728230255,"objectID":"b6a8512e3c5a2bd8cfb72c4aebf5dcfa","permalink":"http://localhost:1313/publication/conference-paper/sam-wav2lip++-enhancing-behavioral-realism-in-synthetic-agents-through-audio-driven-speech-and-action-refinement/","publishdate":"2024-10-06T15:57:35Z","relpermalink":"/publication/conference-paper/sam-wav2lip++-enhancing-behavioral-realism-in-synthetic-agents-through-audio-driven-speech-and-action-refinement/","section":"publication","summary":"Digital human generation is a forward-looking field in technology. Despite significant progress in the generation of speaking facial videos, many challenges remain unaddressed. Issues such as unnatural head movements, distorted expressions, artifacts in generated videos, and uncoordinated limb movements persist. Most current efforts are focused on specific individuals, with enhancements often limited to head movements without further advancing the overall behavioral actions of digital humans. In this context, we introduce a new dataset, CFMD, and a novel model, SAM-Wav2lip++, capable of generating consistent, audio-synchronized lip and behavior action videos from a single reference image of any identity. This work features three main innovative components:(1) a contrastive lip-sync discriminator for precise lip synchronization, (2) a generator for the synthesis of sound-action consistency, and (3) the SAM module for facial refinement operations. Through extensive experiments and user studies, our results demonstrate that our model can synthesize digital human videos of impressively high perceptual quality that accurately sync lip movements and behavioral actions with the input audio, substantially outperforming the state-of-the-art baselines evaluations.","tags":[],"title":"SAM-Wav2lip++: Enhancing Behavioral Realism in Synthetic Agents Through Audio-Driven Speech and Action Refinement","type":"publication"},{"authors":["Jingxuan Wei","Cheng Tan","Zhangyang Gao"],"categories":null,"content":"","date":1724342255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724342255,"objectID":"5016187a08ac2972081338576beb971d","permalink":"http://localhost:1313/publication/conference-paper/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/","publishdate":"2024-08-22T15:57:35Z","relpermalink":"/publication/conference-paper/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Interpretable and Generalizable Spatiotemporal Predictive Learning with Disentangled Consistency","type":"publication"},{"authors":["Cheng Tan","Jingxuan Wei","Zhangyang Gao"],"categories":null,"content":"","date":1719975407,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719975407,"objectID":"c533e302022d113ebaf7de5b1187c5da","permalink":"http://localhost:1313/publication/conference-paper/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/","publishdate":"2024-07-03T02:56:47Z","relpermalink":"/publication/conference-paper/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training","type":"publication"},{"authors":["Jingxuan Wei","Linzhuang Sun","Yichong Leng"],"categories":null,"content":"","date":1713860996,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713860996,"objectID":"a4880609371d7614a9c9b5ae98ffb33f","permalink":"http://localhost:1313/publication/conference-paper/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/","publishdate":"2024-04-23T08:29:56Z","relpermalink":"/publication/conference-paper/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Sentence-Level or Token-Level: A Comprehensive Study on Knowledge Distillation","type":"publication"},{"authors":["Bihui Yu","Linzhuang Sun","Jingxuan Wei"],"categories":null,"content":"","date":1699199855,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699199855,"objectID":"161653b5f8226866df9c72c8328d2d6e","permalink":"http://localhost:1313/publication/conference-paper/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/","publishdate":"2023-11-05T15:57:35Z","relpermalink":"/publication/conference-paper/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"TED-CS: Textual Enhanced Sensitive Video Detection with Common Sense Knowledge","type":"publication"},{"authors":["Jingxuan Wei","Cheng Tan","Zhangyang Gao"],"categories":null,"content":"","date":1690300655,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690300655,"objectID":"de5b8aa47f8fbb569e6d56188986d0b0","permalink":"http://localhost:1313/publication/conference-paper/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/","publishdate":"2023-07-25T15:57:35Z","relpermalink":"/publication/conference-paper/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"http://localhost:1313/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"http://localhost:1313/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"http://localhost:1313/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"},{"authors":["Bihui Yu","Jingxuan Wei","Bo Yu"],"categories":null,"content":"","date":1648137455,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648137455,"objectID":"0dfd25d58f797be264bf114aa4df83d2","permalink":"http://localhost:1313/publication/conference-paper/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/","publishdate":"2022-03-24T15:57:35Z","relpermalink":"/publication/conference-paper/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"Feature-guided Multimodal Sentiment Analysis towards Industry 4.0","type":"publication"}]