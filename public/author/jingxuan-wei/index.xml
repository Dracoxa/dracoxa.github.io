<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jingxuan Wei | 多模态认知智能实验室</title>
    <link>https://dracoxa.github.io/author/jingxuan-wei/</link>
      <atom:link href="https://dracoxa.github.io/author/jingxuan-wei/index.xml" rel="self" type="application/rss+xml" />
    <description>Jingxuan Wei</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 01 Jul 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://dracoxa.github.io/author/jingxuan-wei/avatar_hu_2004da390689bbdc.jpg</url>
      <title>Jingxuan Wei</title>
      <link>https://dracoxa.github.io/author/jingxuan-wei/</link>
    </image>
    
    <item>
      <title>From Words to Structured Visuals: A Benchmark and Framework for Text-to-Diagram Generation and Editing</title>
      <link>https://dracoxa.github.io/publication/conference-paper/from-words-to-structured/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/from-words-to-structured/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jingxuan Wei</title>
      <link>https://dracoxa.github.io/author/jingxuan-wei/</link>
      <pubDate>Tue, 01 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://dracoxa.github.io/author/jingxuan-wei/</guid>
      <description>&lt;p&gt;Jingxuan Wei  is a PhD candidate with research interests in multimodal reasoning, machine translation, and AI for Science. His work focuses on advancing the integration of diverse data modalities and applying artificial intelligence to scientific discovery.&lt;/p&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From Words to Structured Visuals Paper Accepted at CVPR 2025</title>
      <link>https://dracoxa.github.io/event/cvpr/</link>
      <pubDate>Wed, 11 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://dracoxa.github.io/event/cvpr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Faster and More Efficient Subject Image Generation for Text-to-Image Diffusion Models</title>
      <link>https://dracoxa.github.io/publication/conference-paper/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/</link>
      <pubDate>Sun, 06 Oct 2024 15:57:35 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/faster-and-more-efficient-subject-image-generation-for-text-to-image-diffusion-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interpretable and Generalizable Spatiotemporal Predictive Learning with Disentangled Consistency</title>
      <link>https://dracoxa.github.io/publication/conference-paper/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/</link>
      <pubDate>Thu, 22 Aug 2024 15:57:35 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/interpretable-and-generalizable-spatiotemporal-predictive-learning-with-disentangled-consistency/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training</title>
      <link>https://dracoxa.github.io/publication/conference-paper/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/</link>
      <pubDate>Wed, 03 Jul 2024 02:56:47 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/boosting-the-power-of-small-multimodal-reasoning-models-to-match-larger-models-with-self-consistency-training/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sentence-Level or Token-Level: A Comprehensive Study on Knowledge Distillation</title>
      <link>https://dracoxa.github.io/publication/conference-paper/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/</link>
      <pubDate>Tue, 23 Apr 2024 08:29:56 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/sentence-level-or-token-level-a-comprehensive-study-on-knowledge-distillation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TED-CS: Textual Enhanced Sensitive Video Detection with Common Sense Knowledge</title>
      <link>https://dracoxa.github.io/publication/conference-paper/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/</link>
      <pubDate>Sun, 05 Nov 2023 15:57:35 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/ted-cs-textual-enhanced-sensitive-video-detection-with-common-sense-knowledge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework</title>
      <link>https://dracoxa.github.io/publication/conference-paper/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/</link>
      <pubDate>Tue, 25 Jul 2023 15:57:35 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/enhancing-human-like-multi-modal-reasoning-a-new-challenging-dataset-and-comprehensive-framework/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feature-guided Multimodal Sentiment Analysis towards Industry 4.0</title>
      <link>https://dracoxa.github.io/publication/conference-paper/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/</link>
      <pubDate>Thu, 24 Mar 2022 15:57:35 +0000</pubDate>
      <guid>https://dracoxa.github.io/publication/conference-paper/feature-guided-multimodal-sentiment-analysis-towards-industry-4.0/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
